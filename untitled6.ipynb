{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
      "to set the GPU flag to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '21220' (I am process '6296')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete C:\\Users\\Administrator\\AppData\\Local\\Theano\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.7.4-64\\lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '21220' (I am process '6296')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete C:\\Users\\Administrator\\AppData\\Local\\Theano\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.7.4-64\\lock_dir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 0: validation accuracy 98.94%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.03%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 1: validation accuracy 99.05%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.16%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 2: validation accuracy 99.25%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 3: validation accuracy 99.25%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.23%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 4: validation accuracy 99.30%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 5: validation accuracy 99.25%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 6: validation accuracy 99.18%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 7: validation accuracy 99.30%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.18%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Training mini-batch number 220000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 8: validation accuracy 99.29%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 9: validation accuracy 99.21%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "from network3 import ReLU\n",
    "expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"B:/模式识别/mnist_expanded.pkl.gz\")\n",
    "net = Network([\n",
    "    ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "            filter_shape=(20, 1, 5, 5), \n",
    "            poolsize=(2, 2), \n",
    "            activation_fn=ReLU),\n",
    "    ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "            filter_shape=(40, 20, 5, 5), \n",
    "            poolsize=(2, 2), \n",
    "            activation_fn=ReLU),\n",
    "    FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "    FullyConnectedLayer(n_in=100, n_out=100, activation_fn=ReLU),\n",
    "    SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
    "    validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
